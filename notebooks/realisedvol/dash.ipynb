{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive charts for understanding volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Saeed Amen (@thalesians) - Managing Director & Co-founder of the Thalesians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the sample frequency for computing realised volatility will change final result. In this study, we show how we can create an interactive study for users to change the sampling frequency and period window to see how realised volatility changes.\n",
    "\n",
    "We can do this using Dash which can be downloaded [here](https://github.com/chriddyp/dash/). Dash makes it easy to create Flask, JS, and CSS boilerplate for interactive, web-based visualization apps in Python. Also take a look at [this](http://moderndata.plot.ly/create-a-plotly-dashboards-in-under-10-minutes/) which shows how to setup your own cloud instance.\n",
    "\n",
    "We shall be using Python, together with Plotly for plotting. Plotly is a free web-based platform for making graphs. You can keep graphs private, make them public, and run Plotly on your [Plotly Enterprise on your own servers](https://plot.ly/product/enterprise/). You can find more details [here](https://plot.ly/python/getting-started/).\n",
    "\n",
    "We shall be using market data from Bloomberg (using Brian Smith's TIA wrapper). We have also written the code to allow importation of market data from CSV files (for example if you've like to use intraday data from an FX broker) and other online sources. For more information on how to access Bloomberg via Python, please take a look at [this](https://plot.ly/ipython-notebooks/ukelectionbbg/), where I discussed how to use Bloomberg data to do an event study for price action around UK general elections. I have reused some of the code from that earlier project and also added a few extra features to some of that code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* bbg_com - low level interaction with BBG COM object (adapted for Python 3.4) (which we are simply calling)\n",
    "* datadownloader - wrapper for BBG COM, Quandl, Yahoo and CSV access to data\n",
    "* realisedvolslider - interactive analysis of realised volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the market data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the DataDownloader class, which acts a wrapper for various market data sources. The idea is to decouple the precise vendor implementations with our higher level code. This code can be used to download historic market data. For daily historic data we use \"download_time_series\" which has support Bloomberg, Quandl, Yahoo and CSV data sources. For intraday historic data, Bloomberg and CSV data sources are implemented. Obviously, if your CSV files have different date formats, you can edit the code to reflect them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for time series manipulation\n",
    "import pandas\n",
    "import pandas.io.data as web\n",
    "\n",
    "import datetime\n",
    "\n",
    "class DataDownloader:    \n",
    "    def download_time_series(self, vendor_ticker, pretty_ticker, start_date, source, csv_file = None,\n",
    "                             freq = 'daily', freq_no = 1):\n",
    "        if not(isinstance(start_date, list)):\n",
    "            start_date = [start_date]\n",
    "\n",
    "        if freq == 'daily':\n",
    "            if source == 'Quandl':\n",
    "                import Quandl\n",
    "                # Quandl requires API key for large number of daily downloads\n",
    "                # https://www.quandl.com/help/api\n",
    "                spot = Quandl.get(vendor_ticker)\n",
    "                spot = pandas.DataFrame(data = spot['Value'], index = spot.index)\n",
    "                spot.columns = [pretty_ticker]\n",
    "            elif source == 'Yahoo':\n",
    "                finish_date = datetime.datetime.utcnow()\n",
    "                finish_date = datetime.datetime(finish_date.year, finish_date.month, finish_date.day, 0, 0, 0)\n",
    "\n",
    "                spot = web.DataReader(vendor_ticker, 'yahoo', start_date[0], finish_date)\n",
    "                spot = pandas.DataFrame(data = spot['Close'].values, index = spot.index, columns = [pretty_ticker])\n",
    "\n",
    "                spot.index = pandas.DatetimeIndex(spot.index)\n",
    "\n",
    "            elif source == 'Bloomberg':\n",
    "                from egthalesians.plotly.helper.bbg_com import HistoricalDataRequest\n",
    "                req = HistoricalDataRequest([vendor_ticker], ['PX_LAST'], start = start_date[0])\n",
    "                req.execute()\n",
    "\n",
    "                spot = req.response_as_single()\n",
    "                spot.columns = [pretty_ticker]\n",
    "            elif source == 'CSV':\n",
    "                dateparse = lambda x: pandas.datetime.strptime(x, '%Y-%m-%d')\n",
    "\n",
    "                # in case you want to use a source other than Bloomberg/Quandl\n",
    "                spot = pandas.read_csv(csv_file, index_col=0, parse_dates=0, date_parser=dateparse)\n",
    "\n",
    "        elif freq == 'intraday':\n",
    "            if source == 'Bloomberg':\n",
    "                from bbg_com import IntrdayBarRequest\n",
    "                req = IntrdayBarRequest(vendor_ticker, freq_no, start = start_date[0])\n",
    "\n",
    "                req.execute()\n",
    "\n",
    "                spot = req.response\n",
    "                spot.columns = [pretty_ticker + '.' + x for x in spot.columns]\n",
    "\n",
    "                spot = pandas.DataFrame(data = spot[pretty_ticker + \".close\"].values,\n",
    "                                        index = spot.index, columns = [pretty_ticker + \".close\"])\n",
    "\n",
    "            elif source == 'CSV':\n",
    "                dateparse = lambda x: pandas.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "                # in case you want to use a source other than Bloomberg/Quandl etc\n",
    "                try:\n",
    "                    spot = pandas.read_csv(csv_file, index_col = 0, parse_dates = 0, date_parser = dateparse)\n",
    "                except:\n",
    "                    dateparse = lambda x: pandas.datetime.strptime(x, '%d/%m/%Y %H:%M:%S')\n",
    "                    spot = pandas.read_csv(csv_file, index_col = 0, parse_dates = 0, date_parser = dateparse)\n",
    "\n",
    "        return spot\n",
    "    \n",
    "        DataDownloader.download_time_series = download_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive volatility study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to import all the necessarily modules, in particular note the use of Flash and Dash. We also import various libraries like Pandas which are necessary for time series manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for time series/maths\n",
    "import pandas\n",
    "import math\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "# Flask application\n",
    "from flask import Flask, render_template\n",
    "from flask.ext.socketio import SocketIO, emit\n",
    "\n",
    "# for plotting\n",
    "import json\n",
    "import plotly\n",
    "\n",
    "# Dash components\n",
    "import dash.utils as utils\n",
    "from dash.components import element as el\n",
    "from dash.components import graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a wrapper function to download EUR/USD spot data, that is needed for our realised volatility calculation. Users can choose either to use Bloomberg or a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    ticker = 'EURUSD' # will use in plot titles later (and for creating Plotly URL)\n",
    "\n",
    "    ##### download intraday EUR/USD data from Bloomberg or CSV file\n",
    "    # source = \"Bloomberg\"\n",
    "    source = \"CSV\"\n",
    "\n",
    "    csv_file = None\n",
    "\n",
    "    data_downloader = DataDownloader()\n",
    "    start_date = datetime.datetime.utcnow() - timedelta(days = 120)\n",
    "    freq = 'intraday'\n",
    "\n",
    "    if source == 'Bloomberg':\n",
    "        vendor_ticker = 'EURUSD BGN Curncy'\n",
    "    elif source == 'CSV':\n",
    "        # you can get free FX intraday data from Gain Capital (if you don't have Bloomberg)\n",
    "        vendor_ticker = 'EURUSD'\n",
    "        csv_file = 'EURUSD.csv'\n",
    "\n",
    "    return data_downloader.download_time_series(vendor_ticker, ticker, start_date, source, csv_file = csv_file, freq = freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the general properties for the Flask application. We also define the HTML page, including the header, various sliders and a text box. Users will be able to change the \"period\" slider to change the window used for the volatility computation. Similarly, they can change the \"frequency\" slider to change the sampling frequency. Users can type in a plot title into the text box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define properties for application\n",
    "name = 'dash-realised-vol-slide'\n",
    "app = Flask(name)\n",
    "app.debug = True\n",
    "app.config['key'] = 'secret'\n",
    "socketio = SocketIO(app)\n",
    "spot = load_data()\n",
    "graph_id = 'realised-vol-slider'\n",
    "\n",
    "# write the HTML \"includes\" blocks to /templates/runtime/dash-1-hello-world\n",
    "# alternatively, include the HTML yourself in that folder\n",
    "utils.write_templates(\n",
    "    {\n",
    "        'header': [\n",
    "            el('H1', {}, 'Dash to investigate realised vol')\n",
    "        ],\n",
    "\n",
    "        'controls': [\n",
    "            el('label', {}, 'Frequency 5 to 60 mins'),\n",
    "            el('input', {\n",
    "                'type': 'range',\n",
    "                'class': 'u-full-width show-values',\n",
    "                'name': 'frequency',\n",
    "                'value': 0,\n",
    "                'min': 5,\n",
    "                'max': 60,\n",
    "                'step': 5\n",
    "            }),\n",
    "            el('label', {}, 'Period 1 to 20 days'),\n",
    "            el('input', {\n",
    "                    'type': 'range',\n",
    "                    'class': 'u-full-width show-values',\n",
    "                    'name': 'period',\n",
    "                    'value': 0,\n",
    "                    'min': 1,\n",
    "                    'max': 20,\n",
    "                    'step': 1\n",
    "                }),\n",
    "            el('label', {}, 'Title'),\n",
    "            el('input', {\n",
    "                'type': 'text',\n",
    "                'name': 'title',\n",
    "                'placeholder': 'Type away',\n",
    "                'class': 'u-full-width'\n",
    "            }, '')\n",
    "        ],\n",
    "\n",
    "        'main_pane': [\n",
    "            graph(graph_id)\n",
    "        ]\n",
    "    }, name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the default HTML file to use for our rendering. We have used one included as a template in Dash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('layouts/layout_single_column_and_controls.html',\n",
    "                           app_name = name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will be called each time the user changes the values of the sliders. It recalculates the realised volatility dependent on the specified \"period\" and \"frequency\" sliders. It is then pushed to Plotly as JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@socketio.on('replot')\n",
    "def replot(app_state):\n",
    "    print(app_state)\n",
    "    frequency = float(app_state['frequency'])\n",
    "    period = float(app_state['period'])\n",
    "    period_mins = period * (1440.0 / frequency)\n",
    "\n",
    "    # resample data for minute frequency specified\n",
    "    resampled = spot.loc[spot.index.minute % frequency == 0]\n",
    "    resampled = resampled.dropna()\n",
    "\n",
    "    # calculate returns (need for realised volatility calculation)\n",
    "    rets = resampled / resampled.shift(1) - 1\n",
    "\n",
    "    # calculate realised volatility (careful with annualisation factor!)\n",
    "    vol = pandas.rolling_std(rets, period_mins) * math.sqrt(252.0 * (1440.0 / frequency)) * 100\n",
    "\n",
    "    # resample to 60 minute data (quicker to plot)\n",
    "    to_plot = vol.loc[vol.index.minute % 60 == 0]\n",
    "\n",
    "    x = pandas.to_datetime(to_plot.index.values, format='%Y-%m-%d %H:%M')\n",
    "    y = to_plot.ix[:,0]\n",
    "\n",
    "    # define graph in JSON format\n",
    "    messages = [\n",
    "        {\n",
    "            'id': graph_id,\n",
    "            'task': 'newPlot',\n",
    "            'data': [{\n",
    "                'x': x,\n",
    "                'y': y\n",
    "            }],\n",
    "            'layout': {\n",
    "                'xaxis': {\n",
    "                    'title' : 'Date'\n",
    "                },\n",
    "                'yaxis': {\n",
    "                    'title' : 'Vol'\n",
    "                },\n",
    "                'title': app_state.get('title', '') + 'freq = ' + str(frequency) + ' mins, period = '\n",
    "                         + str(period) + ' days, ' + str(period_mins) + ' mins'\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # post JSON message\n",
    "    emit('postMessage', json.dumps(messages, cls = plotly.utils.PlotlyJSONEncoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were running this in practice, we need to kick off the Flask based webserver. The below line of code does this (we have commented this out, because we need to do this outside the jupyter notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# socketio.run(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the app in action below in an animated gif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://imgur.com/p1anUG4.gif\" width=\"750\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='http://imgur.com/p1anUG4.gif', width=750)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biography\n",
    "\n",
    "Saeed Amen is the managing director and co-founder of the Thalesians. He has a decade of experience creating and successfully running systematic trading models at Lehman Brothers, Nomura and now at the Thalesians. Independently, he runs a systematic trading model with proprietary capital. He is the author of Trading Thalesians – What the ancient world can teach us about trading today (Palgrave Macmillan). He graduated with a first class honours master’s degree from Imperial College in Mathematics & Computer Science. He is also a fan of Python and has written an extensive library for financial market backtesting called PyThalesians, which is partially open sourced - available on the [Thalesians GitHub page](https://github.com/thalesians)\n",
    "\n",
    "Follow the Thalesians on Twitter @thalesians and get my book on Amazon [here](http://www.amazon.co.uk/Trading-Thalesians-Saeed-Amen/dp/113739952X). You can also join our Thalesians Meetup.com group [here](http://www.meetup.com/thalesians) - we do quant finance events in a number of cities including London, New York, Budapest, Prague and Frankfurt.\n",
    "\n",
    "The Thalesians website can be found [here](http://www.thalesians.com)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
